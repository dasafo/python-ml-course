{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medidas básicas de la estadística descriptiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/medidas_estidistica_descriptiva.jpg\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1    Medidas de centralización\n",
    "\n",
    "Las **medidas de tendencia central** son las que dan un valor representativo a todas las observaciones. Algunas de las más importantes son:\n",
    "\n",
    "- La **media aritmética** o **valor medio**\n",
    "$$\\bar{x} = \\frac{\\sum_{i=1}^nx_i}{n}=\\frac{\\sum_{j=1}^kn_jX_j}{n}=\\sum_{j=1}^kf_jX_j$$\n",
    "- La **mediana**, que representa el valor central en la lista ordenada de observaciones.\n",
    "- La **moda** es el valor (o valores) de máxima frecuencia (absoluta o relativa, el resultado será el mismo).\n",
    "\n",
    "## La mediana\n",
    "\n",
    "La definición formal de la mediana es la siguiente. Denotando por $$x_{(1)}\\le x_{(2)}\\le\\dots\\le x_{(n)}$$ los datos de la variable cuantitativa ordenados de menor a mayor, la mediana es\n",
    "\n",
    "- Si $n$ par, la medio de los dos datos centrales $$\\frac{x_{(\\frac{n}{2})}+x_{(\\frac{n}{2}+1)}}{2}$$\n",
    "- Si $n$ impar, el dato central $x_{(\\frac{n+1}{2})}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Vamos a generar una lista de números:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar números aleatorios\n",
    "import random\n",
    "random.seed(0)\n",
    "A= (random.sample(range(100000), 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53312.01666666667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cálculo media\n",
    "mean=np.mean(A)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56016.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cálculo mediana\n",
    "np.median(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeResult(mode=array([149]), count=array([1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cálculo moda\n",
    "from scipy import stats \n",
    "stats.mode(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2 Frecuencias de datos cuantitativos\n",
    "\n",
    "En general, supongamos que tenemos $n$ observaciones de una propiedad que se mide con un número real y obtenemos la variable cuantitativa formada por los datos \n",
    "$$x_1,\\dots, x_n$$\n",
    "\n",
    "Sean ahora $X_1,\\dots,X_k$ los valores distintos que aparecen en esta lista de datos y considerémoslos ordenados\n",
    "$$X_1<X_2<\\cdots<X_k$$\n",
    "\n",
    "Entonces, en esta variable cuantitativa\n",
    "\n",
    "- La frecuencia absoluta de $X_i$ es el número $n_i$ de elementos que son iguales a $X_i$\n",
    "- La frecuencia relativa de $X_i$ es $f_i=\\frac{n_i}{n}$\n",
    "- La frecuencia absoluta acumulada de $X_i$ es $N_i=\\sum_{j=1}^in_j$\n",
    "- La frecuencia relativa acumulada de $X_i$ es $F_i=\\frac{N_i}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Medidas de posición\n",
    "\n",
    "Las **medidas de posición** estiman qué valores dividen las observaciones en unas determinadas proporciones.\n",
    "\n",
    "Los valores que determinan estas posiciones son conocidos como los **cuantiles**.\n",
    "\n",
    "Pensándolo de este modo, la mediana puede interpretarse como una medida de posición, debido a que divide la variable cuantitativa en dos mitades.\n",
    "\n",
    "Dada una proporción $p\\in(0,1)$, el **cuantil de orden $p$** de una variable cuantitativa, $Q_p$, es el valor más pequeño tal que su frecuencia relativa acumulada es mayor o igual a $p$.\n",
    "\n",
    "Dicho de otro modo, si tenemos un conjunto de observaciones $x_1,\\dots,x_n$ y los ordenamos de menor a mayor, entonces $Q_p$ será el número más pequeño que deja a su izquierda (incluyéndose a sí mismo) como mínimo a la fracción $p$ de los datos. Es decir, $p\\cdot n$.\n",
    "\n",
    "Así, ahora es más claro ver que la mediana vendría a ser $Q_{0.5}$, el cuantil de orden 0.5.\n",
    "\n",
    "## Cuantiles\n",
    "\n",
    "Algunos cuantiles tienen nombre propio:\n",
    "\n",
    "- Los **cuartiles** son los cuantiles $Q_{0.25},Q_{0.5}$ y $Q_{0.75}$. Respectivamente, son llamados primer, segundo y tercer cuartil. El primer cuartil, $Q_{0.25}$, será el menor valor que es mayor o igual a una cuarta parte de las observaciones y $Q_{0.75}$, el menor valor que es mayor o igual a tres cuartas partes de los datos observados.\n",
    "- El cuantil $Q_{0.5}$ es la mediana\n",
    "- Los **deciles** son los cuantiles $Q_p$ con $p$ un múltiplo de 0.1.\n",
    "- Los **percentiles** son son los cuantiles $Q_p$ con $p$ un múltiplo de 0.01.\n",
    "\n",
    "La definición de cuantil anteriormente dada es orientativa. La realidad es que, exceptuando el caso de la mediana, no hay consenso sobre cómo deben calcularse los cuantiles. En verdad, existen diferentes métodos que pueden dar lugar a soluciones distintas.\n",
    "\n",
    "Al fin y al cabo, nuestro objetivo no es el de encontrar el primer valor de una muestra cuya frecuencia relativa acumulada en la variable sea mayor o igual a $p$, sino estimar el valor de esta cantidad para el total de la población."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32617.75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percencil 100=p1 0=p0, 0.25 1er cuantil 0.75 3er cuantil\n",
    "np.percentile(A, 25) # return 0.25 percentile, e.g 1er cuantil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Medidas de dispersión\n",
    "\n",
    "Las **medidas de dispersión** evalúan lo dispersos que están los datos. Algunas de las más importantes son:\n",
    "\n",
    "- El **rango** o **recorrido**, que es la diferencia entre el máximo y el mínimo de las observaciones.\n",
    "\n",
    "- El **rango intercuartílico**, que es la diferencia entre el tercer y primer cuartil, $Q_{0.75}-Q_{0.25}$.\n",
    "\n",
    "- La **varianza**, a la que denotaremos por $s^2$, es la media aritmética de las diferencias al cuadrado entre los datos $x_i$ y la media aritmética de las observaciones, $\\bar{x}$. $$s^2 = \\frac{\\sum_{j=1}^n(x_j-\\bar{x})^2}{n}=\\frac{\\sum_{j=1}^kn_j(X_j-\\bar{x})^2}{n}=\\sum_{j=1}^kf_j(X_j-\\bar{x})^2$$.\n",
    "\n",
    "## Medidas de dispersión\n",
    "\n",
    "- La **desviación típica** es la raíz cuadrada positiva de la varianza, $s=\\sqrt{s^2}$.\n",
    "\n",
    "- La **varianza muestral** es la corrección de la varianza. La denotamos por $\\tilde{s}^2$ y se corresponde con\n",
    "$$\\tilde{s}^2 = \\frac{n}{n-1}s^2 = \\frac{\\sum_{j=1}^n(x_i-\\bar{x})^2}{n-1}$$\n",
    "- La **desviación típica muestral**, que es la raíz cuadrada positiva de la varianza muestral, $\\tilde{s} = \\sqrt{\\tilde{s}^2}$\n",
    "\n",
    "## Propiedades de la varianza\n",
    "\n",
    "- $s^2\\ge 0$. Esto se debe a que, por definición, es una suma de cuadrados de números reales.\n",
    "- $s^2 = 0\\Longrightarrow x_j-\\bar{x}=0\\ \\forall j= 1,\\dots,n$. En consecuencia, si $s^2=0$, entonces todos los datos son iguales.\n",
    "- $s^2 =\\frac{\\sum_{j=1}^nx_j^2}{n}-\\bar{x}^2$. Es decir, la varianza es la media de los cuadrados de los datos menos el cuadrado de la media aritmética de estos.\n",
    "\n",
    "## Varianza y varianza muestral\n",
    "\n",
    "La diferencia entre ambas definiciones viene por la interrelación entre la estadística descriptiva y la inferencial.\n",
    "\n",
    "Por un lado, es normal medir cómo varían los datos  cuantitativos mediante su varianza definida como la media aritmética de las distancias al cuadrado de los datos a su valor medio. No obstante, por otro lado, el conjunto de nuestras observaciones, por lo normal, será una muestra de una población mucho mayor y nos interesará estimar entre otras muchas cosas su variabilidad.\n",
    "\n",
    "La varianza de una muestra suele dar valores más pequños que la varianza de la población, mientras que la varianza muestral tiende a dar valores alrededor de la varianza de la población.\n",
    "\n",
    "Esta corrección, para el caso de una muestra grande no es notable. Dividir $n$ entre $n-1$ en el caso de $n$ ser grande no significa una gran diferencia y aún menos si tenemos en cuenta que lo que tratamos es de estimar la varianza de la población, no de calcularla de forma exacta.\n",
    "\n",
    "En cambio, si la muestra es relativamente pequeña (digamos $n<30$), entonces la varianza muestral de la muestra aproxima significativamente mejor la varianza de la población que la varianza.\n",
    "\n",
    "La diferencia entre desviación típica y desviación típica muestral es análoga.\n",
    "\n",
    "\n",
    "## Varianza y desviación típica\n",
    "\n",
    "Nótese que tanto la varianza como la desviación típica dan una información equivalente. Entonces, es comprensible preguntarse por qué se definen ambas medidas si con una basta. Pues bien, las unidades de la varianza (metros, litros, años...), ya sea muestral o no, están al cuadrado, mientras que las de la desviación típica no.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "La varianza y desviación típica, nos indica si los valores se desplazan mucho o poco con respecto\n",
    "de la media.\n",
    "\n",
    "* La **varianza** es como se aleja cada valor de la media. La varianza eleva los valores al cuadrado nos introduce en una nueva dimensión… puede no tener sentido.\n",
    "\n",
    "* La **desviación típica** es la raíz cuadrada de la varianza. Con la desviación típica volvemos a la dimensión original.\n",
    "\n",
    "* El **coeficiente de variación** nos mide la variabilidad relativa entre la desviación típica entre la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810711216.7830557"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#varianza\n",
    "np.var(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28472.991005215023"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#desviación típica\n",
    "std=np.std(A)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.40820472660482"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coeficiente de variacion std/mean*100\n",
    "#variabilidad relativa entre la media y la std, si hay mucha variabilidad será grande el coeficiente.\n",
    "std/mean*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Medidas de asimetría\n",
    "\n",
    "Momento de orden *r*, respecto a la media. El momento de orden *r* son los momentos de distribución respecto a la media.\n",
    "\n",
    " $$m_r = \\frac{\\sum_{i=1}^n(x_i-\\bar{x})^r}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sp # para modelos de asimetria\n",
    "from IPython.display import Image # para incluir imagenes local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Asimetría de Fisher (Sesgo):**\n",
    "\n",
    "<img src=\"img/sesgo.gif\">\n",
    "\n",
    "* Si el coeficiente es **= 0**; Significa que vuestra función es perfectamente simetríca, se distribuye igual, por ejemplo la distribución normal. Raro es que salga cero.\n",
    "\n",
    "* Si el coeficiente es **>0**; Significa que cuánto más positivo es este valor más desplazada está la distribución hacía la izquierda, de modo que tenemos una asimetría positiva, nos queda la media muy por encima de la distribución.\n",
    "\n",
    "* Si el el coeficiente es **<0**; Significa que cuánto más negativo es este valor más desplazado está la distribución hacía la derecha, de modo que tenemos una asimetría negativa, nos queda la media muy por debajo de la distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17284864155126514"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd Moment: Asimetría de Fisher\n",
    "Asimetria=sp.skew(A)\n",
    "Asimetria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Curtosis:**\n",
    "\n",
    "<img src=\"img/curtosis.gif\">\n",
    "\n",
    "* **Mesocúrtica (=0)**:  Distribución perfecta, asemejada a la distribución normal en forma, no en valores. Está compensado tanto el centro como las colas.\n",
    "* **Leptocúrtica (>0)**:  Distribución donde se le concentran mucho los datos en el valor central, y apenas tiene cola.\n",
    "* **Platicúrtica (<0)**:  Distribución donde hay pocos valores que se concentren respecto al valor central (media) y hay muchos que aparecen hacia las colas, se concentran más en los laterales. Existe valor central, pero también hay mucha presencia de colas directamente en la distribución de nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0800693127939995"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4th Moment: Curtosis\n",
    "curtosis=sp.kurtosis(A)\n",
    "curtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parámetros importantes para la regresión lineal (entre otros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/errores_lineal.jpg\" width=\"500\">\n",
    "\n",
    "* <font COLOR=\"red\"><b>SST</b></font> = $SSD+SSR = SSE+SSR$. \n",
    "* <font COLOR=\"red\"><b>SST</b></font> = $\\sum_{i=1}^{n}(y_{i}-\\bar y)^2$. **Suma de los cuadrados totales**. Distancia respecto al promedio. Es la distancia entre los puntos rojos y la recta verde(el promedio).\n",
    "* <font COLOR=\"red\"><b>SSD</b> ó <b>SSE</b></font> = $\\sum_{i=1}^{n}(y_{i}-\\hat y_{i})^2$. **Suma de los cuadrados de las diferencias** ó **Sum of Squares Error(residual)**. Es la diferencia entre los datos originales y las predicciones que el modelo no es capaz de explicar (errores que deberían seguir una distribución normal). Distancia entre los puntos rojos(datos obtenidos) y la recta azul(el modelo)\n",
    "* <font COLOR=\"red\"><b>SSR</b></font> = $\\sum_{i=1}^{n}(\\hat y-\\bar y)^2$. **Suma de los cuadrados de la regresión**. Diferencia entre la recta de regresión y la recta promedio que el modelo busca explicar. Distancia entre la recta verde y la azúl en un punto rojo dado.\n",
    "* <font COLOR=\"red\"><b>MSE</b></font> = $\\frac{SSE}{n-p-1}=\\frac{1}{n-p-1} \\sum_{i=1}^{n}(y_{i}-\\hat y_{i})^2$. **Mean Square Error**.\n",
    "* <font COLOR=\"red\"><b>MSR</b></font> = $\\frac{SSR}{p}=\\frac{1}{p} \\sum_{i=1}^{n}(\\hat y-\\bar y)^2$. **Mean Square Regression**.\n",
    "* <font COLOR=\"red\"><b>RSE</b> ó <b>RMSE</b></font> = $\\sqrt{MSE} = \\sqrt \\frac{SSE}{n-p-1}$. **Error Standard Residual** ó **Root Mean Square Error**.\n",
    "* <font COLOR=\"red\"><b>F</b></font> = $\\frac{MSR}{MSE}$. **F-estadístico**.\n",
    "* <font COLOR=\"red\"><b>$R^2$</b></font> = $\\frac{SSR}{SST}=1-\\frac{SSE}{SST}$. **Coeficiente de determinación** *(entre 0 y 1)*. \n",
    "\n",
    "Con <font COLOR=\"magenta\"><b>$y_i$</b></font> el valor predicho e <font COLOR=\"magenta\"><b>$\\hat y_i = y_i(x)$</b></font> el valor real. <font COLOR=\"magenta\"><b>$p$</b></font> el numero de variables independientes.\n",
    "\n",
    "Lo que nos interesa es: **SSD** sea pequeña (menos distancia habrá entre nuestros valores y el modelo) y que **SSR** se acerque lo máximo posible a **SST**, por ello se define **$R^2$** y cuanto más cerca esté de 1 mejor será el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
