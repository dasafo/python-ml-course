{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contraste de hipótesis\n",
    "\n",
    "Asumimos una hipótesis generalmente relacionada con el valor que tiene que tomar un estimador(si es igual a un número o si es más grande o más pequeño que un cierto valor). A esta suposición que tenemos que hacer, le llamamos **hipótesis nula** ($H_0$), la cual tenemos que verificar si esa afirmación es o no es cierta aplicando una serie de reglas que tienen que ver con la distribución normal(Gauss). A la hipótesis contraria (la que no está contemplada en la hipótesis nula) se le llama **hipótesis alternativa**($H_1$).\n",
    "\n",
    "La **hipótesis nula** es nuestra premisa inicial, la cual tenemos que defender hasta que se demuestre lo contrario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/contrastes_hipotesis_1.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/contrastes_hipotesis_2.jpg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contraste de hipótesis:\n",
    "\n",
    "**1-** Asumimos primero una **hipótesis nula** $\\mu_0$ y alternativa uni o bilateral. \n",
    "\n",
    "**2-** Tomamos una muestra aleatoria simple de `n` ocurrencias.\n",
    "\n",
    "**3-** Calculamos el valor del estimador, en este caso el promedio del parámetro $\\mu_{\\bar{X}}$, aunque también podría ser la proporción por ejemplo.\n",
    "\n",
    "Según el **TCL** (teorema central del límite, la distribución de las medias de la población del parámetro estudiado tiende a una distribución normal). \n",
    "\n",
    "**4-** Dependiendo de si conocemos o no la desviación típica ($\\sigma$) previa de nuestros datos, aplicamos: \n",
    "\n",
    "* **Caso 1:** Conocemos $\\sigma$. Entonces aplicamos el **z-test** (*estadístico Z*) que se usa para convertirlo en un estadístico normal ($\\mu=0$ y $\\sigma=1$).\n",
    "\n",
    "* **Caso 2:** No conocemos $\\sigma$ (es la primera vez que se hace ese estudio, no hay datos históricos o el numero de muestras es tan pequeño que ni siquiera se puede asumir normalidad). En este caso tenemos que modelizar la desviación típica $\\sigma$. El **TCL** deja de ser válido ya que la distribución que surge en estos casos es la **t de Student**. La distribución del valor estandar debe estimarse a la vez que estimamos el promedio y si tenemos una muestra lo sifcientemente grande podemos garantizar dicha convergencia a la *t de Student*.\n",
    "\n",
    "**5-** Se calcula el **p-valor** asociado *(ver abajo)*.\n",
    "\n",
    "**6-** Se compara el *p-valor* y el nivel de significación $\\alpha$ y se decide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/contrastes_hipotesis_3.jpg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad que un valor $X$ tome un valor menor a $Z_1$ es $P_1$ y la probabilidad que un valor $X$ tome un valor menor a $Z_2$ es $P_2$.\n",
    "\n",
    "El **nivel de confianza** es la probabilidad con la que nosotros estamos seguros que la variable aleatoria va a caer ahí dentro. Por ejemplo los *niveles de confianza* para una distribución normal (*z-test*) sería:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/contrastes_hipotesis_4.jpg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cualquier estimador, cualquier variable aleatoria que siga una distribución normal, se puede definir un intervalo de confianza si nosotros fijamos a priori el nivel de confianza (como de grande queremos que sea dicho intervalo).\n",
    "\n",
    "Los intervalos de confianza se pueden ver como umbrales o límites de niveles de aceptación que nosotros estamos dispuestos a aceptar para defender la *hipótesis nula* como verdadera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/contrastes_hipotesis_5.jpg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si entorno al valor que estamos defendiendo de la hipótesis nula ($\\mu_0$) aplicamos un intervalo de confianza centrado en este y el valor de nuestro estimador cae dentro de este rango, estadísticamente mantendremos la *hipótesis nula* como correcta, sino acpetaremos la *hipótesis alternativa*.\n",
    "\n",
    "Para decidir el intervalo de confianza nos basaremos por el estadístico que está llevando el análisis a priori (antes de hacer el test). Si nosotros llamamos a la probabilidad **p**, entonces usaremos un **nivel de significación** $\\alpha=1-p$, que representa la probaiblidad de que la *hipótesis nula* no sea cierta, que suelen tener unos valores muy bajos ($0.1$, $0.05$, ...).\n",
    "\n",
    "Otro valor a tener en cuenta es el **p-valor** (ver *T4 - 1 - Linear Regression - Datos ficticios*) o el valor probabilístico del estadístico de contraste. En este caso si el estadístico de contraste que nos ha devuelto (un Z-text o un t-test, el Z valor o el t valor) es el $Z_0$, entonces se define el **p-valor** como la probabilidad de que la función de distribución supere dicho valor. Por así decir el *p-valor* es la probabilidad máxima de caer por encima de dicho valor.\n",
    "\n",
    "Claro ahora que tenemos tanto el *Z-valor* como el *p-valor* obtenidos siempre asumiendo que la hipótesis nula es verdadera, la única forma que hay de que la hipótesis nula sea aceptada es que el *Z-valor* esté fuera de la región de rechazo, es decir que la hipótesis nula será verdadera, única y exclusivamente, si el *p-valor* es superior al nivel de confianza y esto en el dibujo se ve bien. Este caso concreto sería un contraste de hipótesis lateral por la derecha.\n",
    "\n",
    "Por tanto si el *Z-valor* cae fuera de la región de rechazo, o lo que es lo mismo, el valor es más grande que el nivel de significación. Entonces aceptaremos la hipótesis nula. Sino pues no nos quedará más remedio que aceptar como buena la hipótesis alternativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/contrastes_hipotesis_6.jpg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a la asimetría y a la naturaleza de las distribuciones normales y demás, existen tres tipos posibles de test: Un test por la izquierda o de **cola por la izquierda**, el análisis de la **cola por la derecha** o el **análisis de dos colas**. Tenemos dos formas para decidir, mirando las $Z$ (estadísticos de contraste) o los $p-valor$ y las $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/contrastes_hipotesis_7.jpg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En el ejemplo hemos aplicado un contrasete bilateral por la izquierda.\n",
    "* Vemos que el valor de significación $\\alpha$ es mucho más grande que el valor de $p$ por lo tanto rechazamos la hipótesis del pizzero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
